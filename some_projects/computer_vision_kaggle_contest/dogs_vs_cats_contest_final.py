# -*- coding: utf-8 -*-
"""Dogs_vs_Cats_contest_FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e5NmyIz-O2REw7DXhoVaYR-hmclvn0Dn

# Dogs vs Cats

Обучить модель классификации изображение на 2 класса. Исходные данные и валидация решения на kaggle в рамках контеста Cats vs Dogs. Шаблон ipython-ноутбука для решения можно скачать по [ссылке](https://github.com/a4tunado/lectures/tree/master/006). Решения необходимо прислать в виде ipython-ноутбука с указанием значения метрики на Leaderboard. Задание засчитывается при значениях метрики Log Loss меньше 0.3.
[Датасет](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)

https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.applications import vgg16
from tensorflow.keras.applications import vgg19

from tensorflow.keras.applications import xception

from warnings import filterwarnings
filterwarnings('ignore')

import shutil

from keras.preprocessing.image import ImageDataGenerator
print(tf.__version__)
print(tf.executing_eagerly())

#!unzip dogs-vs-cats-redux-kernels-edition.zip

#!unzip train.zip

#!unzip test.zip

"""## Функции загрузки данных"""

import os
from random import shuffle
from glob import glob

IMG_SIZE = (224, 224)  # размер входного изображения сети

train_files = glob('/content/train/*.jpg')
test_files = glob('/content/test/*.jpg')

# загружаем входное изображение и предобрабатываем
def load_image(path, target_size=IMG_SIZE):
    img = cv2.imread(path)[...,::-1]
    img = cv2.resize(img, target_size)
    return xception.preprocess_input(img)  # предобработка для Xception

# функция-генератор загрузки обучающих данных с диска
def fit_generator(files, batch_size=128):
    batch_size = min(batch_size, len(files))
    while True:
        shuffle(files)
        for k in range(len(files) // batch_size):
            i = k * batch_size
            j = i + batch_size
            if j > len(files):
                j = - j % len(files)
            x = np.array([load_image(path) for path in files[i:j]])
            y = np.array([1. if os.path.basename(path).startswith('dog') else 0.
                          for path in files[i:j]])
            yield (x, y)

# функция-генератор загрузки тестовых изображений с диска
def predict_generator(files):
    while True:
        for path in files:
            yield np.array([load_image(path)])

"""## Визуализирую примеры для обучения"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import pyplot as plt
fig = plt.figure(figsize=(16, 8))
for i, path in enumerate(train_files[:10], 1):
    subplot = fig.add_subplot(2, 5, i)
    subplot.set_title('%s' % path.split('/')[-1])
    img = cv2.imread(path)[...,::-1]
    img = cv2.resize(img, IMG_SIZE)
    plt.imshow(img)

"""## Подготовка данных к обучению"""

# разделим папку data (original train)  на тренировочнуи и валидационную выборки

base_path = '/content/train'
categories = ['CAT' , 'DOG']
def move_images_to_specific_folder(file_path, category):
    for image_name in os.listdir(file_path):
        if category.lower() in image_name:
            shutil.move(os.path.join(base_path, image_name), os.path.join(base_path, category))

# создаем папки для котов и собак
for category in categories:
    path = os.path.join(base_path, category)
    os.mkdir(path)

# переносим файлы по своим категориям
for category in categories:
    move_images_to_specific_folder(base_path, category)

datagen = ImageDataGenerator(rescale=1./255,
                                  rotation_range=25,
                                  #width_shift_range=0.15,
                                  #height_shift_range=0.15,
                                  shear_range=0.15,
                                  zoom_range=0.15,
                                  horizontal_flip=True,
                                  validation_split=0.2) # делим выборку

image_size = 299 #Xception image size
batch_size = 128

train_generator = datagen.flow_from_directory(base_path,
                                              class_mode='binary',
                                              batch_size = batch_size,
                                              target_size=(image_size,image_size),
                                              subset='training', shuffle=True, seed=42)
valid_generator = datagen.flow_from_directory(base_path,
                                              class_mode='binary',
                                              batch_size = batch_size,
                                              target_size=(image_size,image_size),
                                              subset='validation', shuffle=True, seed=42)

"""## Загружаю предобученную модель"""

from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint

input_tensor = Input(shape=(image_size, image_size, 3))

base_model = tf.keras.applications.Xception(
    include_top=False,
    weights="imagenet",
    input_tensor=input_tensor,
    input_shape=(299, 299, 3),
    pooling=None,
    classes=2,
    classifier_activation="sigmoid",
)

base_model.summary()

base_model.trainable = False

"""## Добавляю слои"""

inputs = Input(shape=(299, 299, 3))



x = base_model.output

x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.3)(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dense(2048,
                          activation = 'relu')(x)
x = tf.keras.layers.Dropout(0.3)(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dense(2048,
                          activation = 'relu')(x)
x = tf.keras.layers.Dropout(0.3)(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Dense(256,
                          activation = 'relu')(x)
x = tf.keras.layers.Flatten()(x)

x = tf.keras.layers.Dense(1,  # один выход (бинарная классификация)
                          activation='sigmoid',  # функция активации
                          kernel_regularizer=tf.keras.regularizers.l1(1e-4))(x)

model = Model(inputs = base_model.inputs, outputs = x, name='dogs_vs_cats')

"""## Архитектура модели"""

model.summary()

"""## Компилирую модель и запускаю обучение"""

optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001, epsilon=1e-8)

model.compile(optimizer=optimizer,
              loss='binary_crossentropy',
              metrics=['accuracy'])

early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)
save_best = ModelCheckpoint(filepath = 'best_model.hdf5',verbose=1, save_best_only=True)

history = model.fit_generator(generator=train_generator,
                              steps_per_epoch = 10, #train_generator.samples // batch_size,
                              validation_data = valid_generator,
                              validation_steps = valid_generator.samples // batch_size,
                              epochs = 20, callbacks=[save_best,early_stopping],
                              verbose=1)

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.legend()

#лучшая модель
best_model = tf.keras.models.load_model('best_model.hdf5')
best_model.summary()

"""## Предсказания на проверочной выборке"""

test_pred = best_model.predict(
    predict_generator(test_files), steps=len(test_files))

fig = plt.figure(figsize=(16, 8))
for i, (path, score) in enumerate(zip(test_files[:10], test_pred[:10]), 1):
    subplot = fig.add_subplot(2, 5, i)
    subplot.set_title('%.2f %s' % (score, os.path.basename(path)))
    img = cv2.imread(path)[...,::-1]
    img = cv2.resize(img, IMG_SIZE)
    subplot.imshow(img)

"""## Готовлю данные для отправки"""

import csv
import re

with open('submit.csv', mode = 'w', encoding = 'utf-8') as dst:
  file_writer = csv.writer(dst, delimiter = ',', lineterminator="\r")
  file_writer.writerow(["id", "label"])


  for path, score in zip(test_files, test_pred):
        dst.write('%s,%f\n' % (re.search('(\d+).jpg$', path).group(1), score))
        #dst.write('%s,%s\n' % (i, p))

# Xception score = 0.17516

