# -*- coding: utf-8 -*-
"""multiclass_countries_religion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_r-uxv8q2v6YM5voAs95b9ffAvERPFwe

**Цель:**

Вспомнить и применить знания, полученные на протяжении всего курса. Получить полноценную работу, объединяющую в себе основные методики по работе с данными и алгоритмы машинного обучения.

**Описание задания:**

В лабораторной работе предлагается решить задачу классификации. Данные для выполнения работы можно скачать по ссылке, нажав на Data Folder. В датасете находится информация о флаге и базовых показателях страны. На основе доступной информации решается задача классификации стран по религии. Целевой признак мультиклассовый – religion. Остальные признаки описывают характерные черты флага и самой страны. Подробное описание признаков и их возможные значения можно прочесть на сайте.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""**1. Получаю данные и загружаю в рабочую среду**"""

#!wget 'https://archive.ics.uci.edu/static/public/40/flags.zip'

#!unzip flags.zip

df_data = pd.read_csv('flag.data', header = None)
df_data

"""Вижу, что в данных отсутствуют названия признаков. Посмотрю другой файл, там приведено описание датасета"""

df_names = pd.read_csv('flag.names', sep = ';', header = None)
df_names.values

"""Вижу, что названия признаков и пояснения к ним даются в пункте 7. Всего в датасете 30 признаков. Сформирую список названий признаков, чтобы затем дополнить файл .data и сформировать удобно интерпретируемый и читаемый датафрейм

"""

import re

feature_names = []

for line in df_names[0].iloc[df_names.index[df_names[0] == '7. Attribute Information:'].to_list()[0]+1:df_names.index[df_names[0] == '8. Missing values: None'].to_list()[0]].values:
  string = str(line)

  pattern = r"\d.\s\w+\s"  # Шаблон для поиска названия признака
  match = re.search(pattern, string)
  if match:
      word = match.group()[3:]  # Получение найденного названия
      if '\t' in word:
        word = word[:-1]

      if ' ' in word:
        word = word[:-1]
      feature_names.append(word)

df = pd.read_csv('flag.data', header = None, names = feature_names)
df

"""Исходя из описания признаков, сформирую несколько категорий признаков для более удобной работы с ними в дальнейшем"""

df.columns

for_dummies = ['landmass','zone','language','mainhue','topleft','botright']
digital_categorials = ['red', 'green', 'blue', 'gold', 'white', 'black', 'crescent', 'triangle', 'icon', 'animate', 'text']
continuous = ['area', 'population', 'bars', 'stripes', 'colours', 'circles', 'crosses', 'saltires', 'quarters', 'sunstars']

"""**2. Проведу первичный разведочный анализ данных**

Проверю на пропуски
"""

df.info()

"""Пропусков нет, можно идти дальше

Видно, что есть несколько некатегориальных числовых признаков - area и population, значения которых могут быть нулевыми. Посмотрю на них подробнее.
"""

df[df['population'] == 0]

"""Бросается в глаза тот факт, что страны якобы с отсутствующим населением очень часто также имеют и нулевую площадь. В описании к этим признакам сказано, что значения признаков площади и населения округляются до тысяч квадратных километров и миллионов человек соответственно. А это значит, что население и площадь этих стран меньше 1 млн и 1000 кв. км соответственно. При этом остальные признаки у них заполнены, значит, какую-то информацию они содержат. Более того, мы еще не знаем, насколько важны для модели население и площадь страны. Ну и наконец, в датасете очень мало объектов (194), чтобы еще удалять порядка 50-60 из них, что составляет примерно 30% от общего списка, это очень много.

Поэтому оставляю эти страны в датафрейме

**3. Сделаю несколько визуализаций**

Сначала посмотрю, как связаны между собой площадь и население
"""

sns.set(rc={'figure.figsize':(12,9)})
sns.pairplot(data = df, vars = ['population','area'], hue = 'religion');

"""Несмотря на большое количество точек вблизи 0 по шкале населения, можно увидеть положительную корреляцию

Зная, что зеленый цвет является особым у мусульман, предположу, что он может каким-то образом определять религию страны. Построю визуализацию распределения флагов, содержащих зеленый цвет и аналогичное распределение для стран, где нет зеленого
"""

plt.figure(figsize=(12,9))
plt.hist(df[df['green'] == 1]['religion'], bins = 40, alpha = 0.5)
plt.hist(df[df['green'] != 1]['religion'], bins = 40, alpha = 0.5)

religion_dict = {0:'Catholic',
                 1:'Other Christian',
                 2:'Muslim',
                 3:'Buddhist',
                 4:'Hindu',
                 5:'Ethnic',
                 6:'Marxist',
                 7:'Others'}
#['Catholic', 'Other Christian', 'Muslim', 'Buddhist', 'Hindu','Ethnic', 'Marxist', 'Others']
plt.xlabel(religion_dict)
plt.ylabel('number')
plt.title('Green color in flag impact')
plt.legend(['has green in flag', 'no green in flag'])


plt.show()

"""Вижу, что зеленый цвет во флаге является достаточно важным признаком для определения религии. Практически нет религий, где зеленого цвета было бы примерно поравну с остальными - он либо преобладает, как для мусульманских, индуистских и этнических стран, либо наоборот редко встречается, как в католических, буддистских и марксистских странах

Построю распределение флагов по религиям
"""

plt.figure(figsize=(12,9))
plt.hist(df['religion'], bins = 20)
plt.xlabel('religion')
plt.ylabel('number')
plt.title('Flags by religion distribution')

plt.show()

"""Вижу, что датасет по классам не сбалансирован. Это может быть проблемой при дальнейшем обучении моделей

**4. Построю корреляционную матрицу**
"""

corr = df.corr()
plt.figure(figsize = (26,18))
sns.heatmap(corr, annot = True)
plt.show()

"""**4. Сформирую множества признаков и целевых переменных**"""

X = pd.concat([df[continuous], df[digital_categorials], pd.get_dummies(df[for_dummies])], axis = 1)
X.head()

y = df['religion']
y.head()

y.value_counts()

"""Вижу, что есть классы, где всего 4 объекта. Это станет проблемой при обучении, т.к. это слишком маленькая выборка, из которой еще и необходимо выделить меньшую по размерам выборку для обучения

**5. Построю baseline модель для получения точки отсчета и дальнейшего повышения качества**
"""

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier

X_train, X_test, y_train, y_test = train_test_split(X,
                                                    y,
                                                    test_size = 0.2,
                                                    random_state = 42)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(X_train, y_train)

from sklearn.metrics import classification_report

y_pred_basic = lr.predict(X_test)

print(classification_report(y_test, y_pred_basic))

"""**Теперь начну процесс улучшения**

Объединю 3,4 и 7 классы, чтобы модель смогла обучиться на этом новом классе
"""

def union_classes(x):
  if x in [3,4,7]:
    return 3
  elif x == 6:
    return 5
  elif x == 5:
    return 4
  else:
    return x

df['religion'] = df['religion'].apply(union_classes)

y = df['religion']

y.value_counts()

"""**6. Обучу модель классификации RandomForest для полученных данных**"""

X_train, X_test, y_train, y_test = train_test_split(X,
                                                    y,
                                                    test_size = 0.2,
                                                    random_state = 42)

rfc = RandomForestClassifier(max_depth = 20, min_samples_leaf = 5, n_estimators = 100, n_jobs = -1, random_state = 42)

rfc.fit(X_train, y_train)

y_pred = rfc.predict(X_test)

print(classification_report(y_test, y_pred))

"""**7. Проведу нормализацию признаков**

Поскольку в датасете есть только 2 некатегориальных признака - area и population - нормализую только их
"""

from sklearn.preprocessing import MinMaxScaler

#X_scaled = MinMaxScaler().fit_transform(X)

X_scaled_new = MinMaxScaler().fit_transform(X[['area','population']])
X_scaled_new = pd.DataFrame(data = X_scaled_new, columns = X[['area','population']].columns)
X_part = X.drop(columns = ['area','population'])
X_scaled = pd.concat([X_scaled_new, X_part], axis = 1)

X_scaled_train, X_scaled_test, y_train, y_test = train_test_split(X_scaled,
                                                                  y,
                                                                  test_size = 0.2,
                                                                  stratify = y,
                                                                  random_state = 42)

rfc.fit(X_scaled_train, y_train)

y_pred_sc = rfc.predict(X_scaled_test)

print(classification_report(y_test, y_pred_sc))

"""После проведения нормализации результаты на тесте по всем метрикам не изменились. Зато получилось классифицировать все классы с той или иной степенью точности. Пробую дальше.

**8. Попробую сбалансировать классы**

Для этого поэкспериментирую с 2 вещами - сначала передам в модель RandomForest взвешенные классы с помощью compute_class_weights, а затем проведу oversampling
"""

from sklearn.utils.class_weight import compute_class_weight

class_weights = compute_class_weight('balanced', classes = np.unique(y), y = y)

class_weights

rfc_b = RandomForestClassifier(max_depth=20, min_samples_leaf=5, n_estimators = 100, n_jobs = -1, random_state = 42, class_weight=dict(enumerate(class_weights)))

rfc_b.fit(X_scaled_train, y_train)

y_pred_b = rfc_b.predict(X_scaled_test)
print(classification_report(y_test, y_pred_b))

"""Вижу, что с помощью взвешивания классов метрики пока что наилучшие. Попробую oversampling, а конкретно - метод SMOTE"""

from imblearn.over_sampling import SMOTE

smote = SMOTE(k_neighbors=5)

X_resampled_train, y_resampled_train = smote.fit_resample(X_scaled_train, y_train)

y_resampled_train.value_counts()

"""Теперь классы полностью сбаалансированы и можно переходить к обучению"""

rfc.fit(X_resampled_train, y_resampled_train)

y_pred_resampled = rfc.predict(X_scaled_test)
print(classification_report(y_test, y_pred_resampled))

"""Вижу, что oversampling сработал хуже, чем простая балансировка весов, с точки зрения accuracy. Тем не менее, пока что лучшим результатом остается базовый randomforest с отбалансированными весами и нормализованными данными

**9. Теперь отберу признаки**

Сначала посмотрю на важность признаков из модели случайного леса

Чтобы понять, какие признаки надо убрать, добавлю новый случайный признак random_feature
"""

X_scaled_train_df = pd.DataFrame(data = X_scaled_train, columns=X.columns)

#X_scaled_train = X_scaled_train.astype('int64')
X_scaled_train_df['RANDOM_FEATURE'] = np.random.random(X_scaled_train.shape[0])

rfc_b.fit(X_scaled_train_df, y_train)

rfc_b.feature_importances_

plt.figure(figsize = (12,9))
plt.barh(np.arange(len(rfc_b.feature_importances_)), rfc_b.feature_importances_)
plt.xlabel('features')
plt.ylabel('coefs')
plt.yticks(np.arange(len(X_scaled_train_df.columns)), X_scaled_train_df.columns);

"""Сформирую список признаков, чья значимость оказалась выше значимости случайного признака - это population, area, language, zone, landmass"""

cols = []
for i in [0,1,21,23]:
  cols.append(X.columns[i])

cols

cols_upd = cols
cols_upd.append('zone')

X_scaled_train = pd.DataFrame(data = X_scaled_train, columns = X.columns)
X_scaled_test = pd.DataFrame(data = X_scaled_test, columns = X.columns)

rfc_b.fit(X_scaled_train[cols_upd], y_train)
y_pred = rfc_b.predict(X_scaled_test[cols_upd])
print(classification_report(y_test, y_pred))

"""Оказалось, что с полным набором признаков модель показывает лучший accuracy, чем с отобранными. Значит оставлю полный набор, но проверю себя в дальнейшем через параметр max_features в методе для поиска оптимальных метапараметров GridSearch

**10. Теперь подберу оптимальные метапараметры модели**
"""

from sklearn.model_selection import GridSearchCV

params = {'n_estimators':[50, 100, 200, 500],
          'max_depth':[5,10,15,20],
          'min_samples_leaf':[2,3,4,5],
          'random_state':[42],
          'n_jobs':[-1],
          #'class_weight':[dict(enumerate(class_weights))],
          'max_features':[4,5,None]
          }

cv = StratifiedKFold(n_splits = 3)

X_resampled_train = pd.DataFrame(data = X_resampled_train, columns = X_train.columns)

y_resampled_train

rfc_grid = GridSearchCV(RandomForestClassifier(), param_grid = params, verbose = 1, n_jobs = -1, cv = cv)
rfc_grid.fit(X_resampled_train, y_resampled_train)

rfc_grid.best_estimator_

rfc_grid.best_score_

y_pred = rfc_grid.predict(X_scaled_test)

print(classification_report(y_test, y_pred))

rfc_grid.best_estimator_.score(X_scaled_test, y_test)

#------------RandomizedSearchCV--------------------------------------------

from sklearn.model_selection import RandomizedSearchCV

rfc_rand = RandomizedSearchCV(RandomForestClassifier(), params, verbose = 1, n_jobs = -1, cv = cv)
rfc_rand.fit(X_resampled_train, y_resampled_train)

rfc_rand.best_estimator_

rfc_rand.best_score_

y_pred = rfc_rand.predict(X_scaled_test)

print(classification_report(y_test, y_pred))

rfc_rand.best_estimator_.score(X_scaled_test, y_test)

"""**11. Воспользуюсь бустингом и стэкингом**"""

from sklearn.ensemble import GradientBoostingClassifier

boosting = GradientBoostingClassifier(n_estimators=100,
                                     random_state=42)

boosting.fit(X_resampled_train, y_resampled_train)

boosting.score(X_resampled_train, y_resampled_train)

boosting.score(X_scaled_test, y_test)

"""Попробую найти наиболее оптимальные параметры с помощью GridSearch"""

boosting_params = {
    'n_estimators':[100,200,300],
    'min_samples_split':[5,10,15],
    'min_samples_leaf':[2,3,4,5],
    'max_depth':[10,20,30],
    'max_features':[4,5,None],
    'random_state':[42]
}

cv = StratifiedKFold(n_splits = 3)

boosting_grid = GridSearchCV(GradientBoostingClassifier(), param_grid = boosting_params, verbose = 1, n_jobs = -1, cv = cv)
boosting_grid.fit(X_resampled_train, y_resampled_train)

boosting_grid.best_estimator_

boosting_grid.best_score_

y_pred = boosting_grid.predict(X_scaled_test)

print(classification_report(y_test, y_pred))

boosting_grid.best_estimator_.score(X_scaled_test, y_test)

"""Похоже что изначальные метапараметры отработали лучше, чем с помощью GridSearch, оставлю изначальный бустинг, и попробую xgboost"""

from xgboost import XGBClassifier

xgb = XGBClassifier(random_state=42)
xgb.fit(X_resampled_train, y_resampled_train)

xgb.score(X_resampled_train, y_resampled_train)

xgb.score(X_scaled_test, y_test)

"""Получил почти тот же результат, теперь попробую catboost"""

# !pip install catboost

from catboost import CatBoostClassifier

cat = CatBoostClassifier(random_state=42)
cat.fit(X_scaled_train, y_train)

cat.score(X_resampled_train, y_resampled_train)

cat.score(X_scaled_test, y_test)

"""Ну и наконец, попробую стэкинг из логистической регрессии, случайного леса и градиентного бустинга с метапараметрами, подобранными в GridSearch из best_estimator_"""

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

stacking_cl = StackingClassifier(
    [
        ('LogisticRegression', LogisticRegression()),
        ('RandomForest', RandomForestClassifier(max_depth=20, min_samples_leaf=5, n_estimators = 100, n_jobs = -1, random_state = 42)),
        ('Boosting', GradientBoostingClassifier(max_depth=10, max_features=5, min_samples_leaf=3,
                           n_estimators=50, random_state=42))
    ])

stacking_cl.fit(X_resampled_train, y_resampled_train)

print(f'Score on train  {stacking_cl.score(X_resampled_train, y_resampled_train)}')
print(f'Score on test  {stacking_cl.score(X_scaled_test, y_test)}')

for i in stacking_cl.named_estimators:
    print(f'Score on train  with model {i} {stacking_cl.named_estimators_[i].score(X_resampled_train, y_resampled_train)}')
    print(f'Score on test  with model {i} {stacking_cl.named_estimators_[i].score(X_scaled_test, y_test)}')

"""**ИТОГИ**

---

**Стартовая точка - базовая логистическая регрессия на необработанных данных со значением accuracy 0.33**
"""

print(classification_report(y_test, y_pred_basic))

"""**Промежуточный итог - RandomForest с различными метапараметрами модели, 2 из 3 бустингов и финальный стэкинг с одинаковым значением accuracy 0.69**

RandomForest на нормализованных данных с отбалансированными классами и вручную подобранными другими метапараметрами
"""

rfc_b.fit(X_scaled_train, y_train)

y_pred_b = rfc_b.predict(X_scaled_test)
print(classification_report(y_test, y_pred_b))

"""RandomForest с подобранными в GridSearch метапараметрами"""

rfc_grid.best_estimator_

print(classification_report(y_test, y_pred))

"""XGboost"""

xgb.score(X_scaled_test, y_test)

"""**Итоговый результат**

Наилучшее качество показала модель градиентного бустинга на нормализованных данных с объединенными в один малочисленными классами после oversampling'а с помощью метода SMOTE
"""

boosting.score(X_scaled_test, y_test)

"""**11. Выводы**

---



Была решена задача многоклассовой классификации с использованием различных методов оптимизации данных и параметров модели. Удалось поднять метрику accuracy с 0.33 для baseline модели логистической регрессии сначала до 0.69 с использованием модели RandomForest, нормализации данных и объединении малочисленных классов, а затем до 0.79 дополнительно с помощью oversampling'а данных и модели градиентного бустинга.

К сожалению, методы поиска оптимальных параметров модели GridSearch и RandomizedSearch не дали ощутимого прироста в качестве, как и отбор наиболее важных признаков из общего числа признаков. Возможно, при продолжении экспериментов с GridSearch и увеличении размеров сетки признаков качество стало бы лучше, но это потребует большего времени и ресурсов моей машины, возможно, значительно больше при незначительном улучшении итогового качества.
"""